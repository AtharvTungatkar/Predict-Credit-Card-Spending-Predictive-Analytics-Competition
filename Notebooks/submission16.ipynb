{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ef8c1e2",
   "metadata": {},
   "source": [
    "Generalised Additive Model with MICE and Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c64bc7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dad67080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('Datasets/analysis_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a200100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['gender', 'marital_status', 'education_level', 'region', 'employment_status', 'card_type']\n",
      "Numeric columns: ['customer_id', 'age', 'owns_home', 'has_auto_loan', 'annual_income', 'credit_score', 'credit_limit', 'tenure', 'num_transactions', 'avg_transaction_value', 'online_shopping_freq', 'reward_points_balance', 'travel_frequency', 'utility_payment_count', 'num_children', 'num_credit_cards']\n",
      "Train shape before MICE: (32000, 22)\n",
      "Test shape before MICE: (8000, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 3) |                          | Elapsed Time: 0:00:00 ETA:  --:--:--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any NaNs after MICE (train)? 0\n",
      "Any NaNs after MICE (test)?  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33% (1 of 3) |########                  | Elapsed Time: 0:00:07 ETA:   0:00:15\n",
      " 66% (2 of 3) |#################         | Elapsed Time: 0:00:14 ETA:   0:00:07\n",
      "100% (3 of 3) |##########################| Elapsed Time: 0:00:21 Time:  0:00:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¥ GAM + Target Encoding + MICE â€” Test RMSE: 258.4614\n",
      "GAM Test RÂ²: 0.7684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa: F401\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
    "\n",
    "from pygam import LinearGAM, s  # Generalized Additive Model\n",
    "\n",
    "# =========================================================\n",
    "# 1. Setup: target and features\n",
    "# =========================================================\n",
    "df = data.copy()  # assumes `data` exists\n",
    "target_col = \"monthly_spend\"\n",
    "\n",
    "y = df[target_col].reset_index(drop=True)\n",
    "X = df.drop(columns=[target_col]).reset_index(drop=True)\n",
    "\n",
    "# Identify column types\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "print(\"Categorical columns:\", cat_cols)\n",
    "print(\"Numeric columns:\", num_cols)\n",
    "\n",
    "# =========================================================\n",
    "# 2. Trainâ€“test split\n",
    "# =========================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Work on copies\n",
    "X_train_enc = X_train.copy().reset_index(drop=True)\n",
    "X_test_enc = X_test.copy().reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# Ensure categoricals are strings and handle missing\n",
    "if cat_cols:\n",
    "    X_train_enc[cat_cols] = X_train_enc[cat_cols].astype(str).fillna(\"Missing\")\n",
    "    X_test_enc[cat_cols] = X_test_enc[cat_cols].astype(str).fillna(\"Missing\")\n",
    "\n",
    "# =========================================================\n",
    "# 3. Out-of-fold Target Encoding (LEAK-PROOF)\n",
    "# =========================================================\n",
    "def target_encode_train_test(\n",
    "    X_train_df, y_train_ser, X_test_df, cat_columns, n_splits=5, smoothing=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        X_train_te: DataFrame with target-encoded train columns\n",
    "        X_test_te:  DataFrame with target-encoded test columns\n",
    "    \"\"\"\n",
    "    X_train_te = pd.DataFrame(index=X_train_df.index)\n",
    "    X_test_te = pd.DataFrame(index=X_test_df.index)\n",
    "\n",
    "    if not cat_columns:\n",
    "        return X_train_te, X_test_te\n",
    "\n",
    "    y_train_ser = y_train_ser.reset_index(drop=True)\n",
    "    global_mean = y_train_ser.mean()\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # ----- TRAIN (out-of-fold) -----\n",
    "    for col in cat_columns:\n",
    "        oof = pd.Series(index=X_train_df.index, dtype=float)\n",
    "\n",
    "        for tr_idx, val_idx in kf.split(X_train_df):\n",
    "            X_tr = X_train_df.iloc[tr_idx]\n",
    "            X_val = X_train_df.iloc[val_idx]\n",
    "            y_tr = y_train_ser.iloc[tr_idx]\n",
    "\n",
    "            stats = (\n",
    "                y_tr.groupby(X_tr[col])\n",
    "                .agg([\"mean\", \"count\"])\n",
    "                .rename(columns={\"mean\": \"te_mean\", \"count\": \"te_count\"})\n",
    "            )\n",
    "\n",
    "            smoothing_factor = 1 / (1 + np.exp(-(stats[\"te_count\"] - smoothing)))\n",
    "            te_values = global_mean * (1 - smoothing_factor) + stats[\"te_mean\"] * smoothing_factor\n",
    "\n",
    "            oof.iloc[val_idx] = X_val[col].map(te_values)\n",
    "\n",
    "        oof = oof.fillna(global_mean)\n",
    "        X_train_te[col + \"_te\"] = oof\n",
    "\n",
    "    # ----- TEST (full-data encoding) -----\n",
    "    for col in cat_columns:\n",
    "        stats_full = (\n",
    "            y_train_ser.groupby(X_train_df[col])\n",
    "            .agg([\"mean\", \"count\"])\n",
    "            .rename(columns={\"mean\": \"te_mean\", \"count\": \"te_count\"})\n",
    "        )\n",
    "\n",
    "        smoothing_factor_full = 1 / (1 + np.exp(-(stats_full[\"te_count\"] - smoothing)))\n",
    "        te_values_full = global_mean * (1 - smoothing_factor_full) + stats_full[\"te_mean\"] * smoothing_factor_full\n",
    "\n",
    "        test_encoded = X_test_df[col].map(te_values_full).fillna(global_mean)\n",
    "        X_test_te[col + \"_te\"] = test_encoded\n",
    "\n",
    "    return X_train_te, X_test_te\n",
    "\n",
    "X_train_te, X_test_te = target_encode_train_test(\n",
    "    X_train_enc, y_train, X_test_enc, cat_cols, n_splits=5, smoothing=10\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 4. Combine numeric + target-encoded categorical features\n",
    "# =========================================================\n",
    "X_train_num = X_train_enc[num_cols].copy()\n",
    "X_test_num = X_test_enc[num_cols].copy()\n",
    "\n",
    "X_train_final = pd.concat(\n",
    "    [X_train_num.reset_index(drop=True),\n",
    "     X_train_te.reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "X_test_final = pd.concat(\n",
    "    [X_test_num.reset_index(drop=True),\n",
    "     X_test_te.reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"Train shape before MICE:\", X_train_final.shape)\n",
    "print(\"Test shape before MICE:\", X_test_final.shape)\n",
    "\n",
    "# =========================================================\n",
    "# 5. MICE Imputation (IterativeImputer with BayesianRidge)\n",
    "# =========================================================\n",
    "mice = IterativeImputer(\n",
    "    estimator=BayesianRidge(),\n",
    "    max_iter=10,\n",
    "    initial_strategy=\"median\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train_imputed = mice.fit_transform(X_train_final)\n",
    "X_test_imputed = mice.transform(X_test_final)\n",
    "\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed, columns=X_train_final.columns)\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed, columns=X_test_final.columns)\n",
    "\n",
    "print(\"Any NaNs after MICE (train)?\", X_train_imputed.isna().sum().sum())\n",
    "print(\"Any NaNs after MICE (test)? \", X_test_imputed.isna().sum().sum())\n",
    "\n",
    "# =========================================================\n",
    "# 6. Fit a GAM (LinearGAM) on imputed numeric + TE features\n",
    "# =========================================================\n",
    "# Weâ€™ll use one smooth term s(...) per feature.\n",
    "# You can tune lam, n_splines, etc., for better performance.\n",
    "\n",
    "n_features = X_train_imputed.shape[1]\n",
    "terms = sum([s(i) for i in range(n_features)], start=s(0))  # additive smooth terms\n",
    "\n",
    "gam = LinearGAM(terms).gridsearch(\n",
    "    X_train_imputed.values,\n",
    "    y_train.values,\n",
    "    lam=[0.1, 1, 10]  # smoothing penalties to try\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 7. Evaluate on test set\n",
    "# =========================================================\n",
    "y_pred_test = gam.predict(X_test_imputed.values)\n",
    "rmse_gam = root_mean_squared_error(y_test, y_pred_test)\n",
    "print(f\"\\nðŸ”¥ GAM + Target Encoding + MICE â€” Test RMSE: {rmse_gam:.4f}\")\n",
    "\n",
    "# Optional: check RÂ² as well\n",
    "from sklearn.metrics import r2_score\n",
    "r2_gam = r2_score(y_test, y_pred_test)\n",
    "print(f\"GAM Test RÂ²: {r2_gam:.4f}\")\n",
    "\n",
    "# =========================================================\n",
    "# 8. Inspect partial dependence (shape functions) for key features\n",
    "# =========================================================\n",
    "# Example: plot shapes for first few features (requires matplotlib)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_names = X_train_imputed.columns.tolist()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb753016",
   "metadata": {},
   "source": [
    "Gam without Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e30651e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categoricals: ['gender', 'marital_status', 'education_level', 'region', 'employment_status', 'card_type']\n",
      "Numerics: ['customer_id', 'age', 'owns_home', 'has_auto_loan', 'annual_income', 'credit_score', 'credit_limit', 'tenure', 'num_transactions', 'avg_transaction_value', 'online_shopping_freq', 'reward_points_balance', 'travel_frequency', 'utility_payment_count', 'num_children', 'num_credit_cards']\n",
      "Train shape after OHE: (32000, 35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 10) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--\n",
      " 10% (1 of 10) |##                       | Elapsed Time: 0:00:12 ETA:   0:01:55\n",
      " 20% (2 of 10) |#####                    | Elapsed Time: 0:00:25 ETA:   0:01:41\n",
      " 30% (3 of 10) |#######                  | Elapsed Time: 0:00:38 ETA:   0:01:28\n",
      " 40% (4 of 10) |##########               | Elapsed Time: 0:00:51 ETA:   0:01:16\n",
      " 50% (5 of 10) |############             | Elapsed Time: 0:01:04 ETA:   0:01:04\n",
      " 60% (6 of 10) |###############          | Elapsed Time: 0:01:17 ETA:   0:00:51\n",
      " 70% (7 of 10) |#################        | Elapsed Time: 0:01:29 ETA:   0:00:38\n",
      " 80% (8 of 10) |####################     | Elapsed Time: 0:01:42 ETA:   0:00:25\n",
      " 90% (9 of 10) |######################   | Elapsed Time: 0:01:56 ETA:   0:00:12\n",
      "100% (10 of 10) |########################| Elapsed Time: 0:02:09 Time:  0:02:09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¥ GAM Test RMSE: 258.3478\n",
      "ðŸ“ˆ GAM Test RÂ²: 0.7686\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa: F401\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "from pygam import LinearGAM, s\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 1. SETUP â€” Split data\n",
    "# =========================================================\n",
    "df = data.copy()\n",
    "target_col = \"monthly_spend\"\n",
    "\n",
    "y = df[target_col].reset_index(drop=True)\n",
    "X = df.drop(columns=[target_col]).reset_index(drop=True)\n",
    "\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "print(\"Categoricals:\", cat_cols)\n",
    "print(\"Numerics:\", num_cols)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2. OneHotEncode categorical variables\n",
    "# =========================================================\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "X_train_ohe = preprocessor.fit_transform(X_train)\n",
    "X_test_ohe = preprocessor.transform(X_test)\n",
    "\n",
    "# Column names\n",
    "ohe_cols = preprocessor.named_transformers_[\"cat\"].get_feature_names_out(cat_cols)\n",
    "final_cols = list(ohe_cols) + num_cols\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train_ohe, columns=final_cols)\n",
    "X_test_df = pd.DataFrame(X_test_ohe, columns=final_cols)\n",
    "\n",
    "print(\"Train shape after OHE:\", X_train_df.shape)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3. MICE Imputation\n",
    "# =========================================================\n",
    "mice = IterativeImputer(\n",
    "    estimator=BayesianRidge(),\n",
    "    max_iter=10,\n",
    "    initial_strategy=\"median\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train_imp = mice.fit_transform(X_train_df)\n",
    "X_test_imp = mice.transform(X_test_df)\n",
    "\n",
    "X_train_imp = pd.DataFrame(X_train_imp, columns=final_cols)\n",
    "X_test_imp = pd.DataFrame(X_test_imp, columns=final_cols)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 4. Fit GAM\n",
    "# =========================================================\n",
    "n_features = X_train_imp.shape[1]\n",
    "\n",
    "# Build additive smooth terms\n",
    "terms = s(0)\n",
    "for i in range(1, n_features):\n",
    "    terms = terms + s(i)\n",
    "\n",
    "gam = LinearGAM(terms).gridsearch(\n",
    "    X_train_imp.values,\n",
    "    y_train.values,\n",
    "    lam=np.logspace(-3, 3, 10)\n",
    ")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 5. Evaluate GAM\n",
    "# =========================================================\n",
    "y_pred_test = gam.predict(X_test_imp.values)\n",
    "\n",
    "rmse = root_mean_squared_error(y_test, y_pred_test)\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"\\nðŸ”¥ GAM Test RMSE: {rmse:.4f}\")\n",
    "print(f\"ðŸ“ˆ GAM Test RÂ²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17521b09",
   "metadata": {},
   "source": [
    "GAM with Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3560c5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 7) |                          | Elapsed Time: 0:00:00 ETA:  --:--:--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k features for interactions: ['credit_limit', 'annual_income', 'reward_points_balance', 'num_transactions', 'travel_frequency', 'card_type_platinum', 'online_shopping_freq', 'card_type_standard', 'utility_payment_count', 'num_children']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\athar\\anaconda4\\Lib\\site-packages\\pygam\\pygam.py:806: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  diff = np.linalg.norm(self.coef_ - coef_new) / np.linalg.norm(coef_new)\n",
      "c:\\Users\\athar\\anaconda4\\Lib\\site-packages\\pygam\\pygam.py:806: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  diff = np.linalg.norm(self.coef_ - coef_new) / np.linalg.norm(coef_new)\n",
      "c:\\Users\\athar\\anaconda4\\Lib\\site-packages\\pygam\\pygam.py:800: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  np.fill_diagonal(Dinv, d**-1)  # invert the singular values\n",
      "c:\\Users\\athar\\anaconda4\\Lib\\site-packages\\pygam\\pygam.py:800: RuntimeWarning: overflow encountered in reciprocal\n",
      "  np.fill_diagonal(Dinv, d**-1)  # invert the singular values\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 106\u001b[0m\n\u001b[0;32m    101\u001b[0m         terms \u001b[38;5;241m=\u001b[39m terms \u001b[38;5;241m+\u001b[39m te(fi, fj)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# =========================================\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# 6. Fit GAM with interactions (GAÂ²M-lite)\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# =========================================\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m gam \u001b[38;5;241m=\u001b[39m LinearGAM(terms)\u001b[38;5;241m.\u001b[39mgridsearch(\n\u001b[0;32m    107\u001b[0m     X_train_imp\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[0;32m    108\u001b[0m     y_train\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[0;32m    109\u001b[0m     lam\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m    110\u001b[0m )\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSelected Lambda(s):\u001b[39m\u001b[38;5;124m\"\u001b[39m, gam\u001b[38;5;241m.\u001b[39mlam)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# =========================================\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# 7. Evaluate on test set\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# =========================================\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\athar\\anaconda4\\Lib\\site-packages\\pygam\\pygam.py:2054\u001b[0m, in \u001b[0;36mGAM.gridsearch\u001b[1;34m(self, X, y, weights, return_scores, keep_best, objective, progress, **param_grids)\u001b[0m\n\u001b[0;32m   2052\u001b[0m         coef \u001b[38;5;241m=\u001b[39m models[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[0;32m   2053\u001b[0m         gam\u001b[38;5;241m.\u001b[39mset_params(coef_\u001b[38;5;241m=\u001b[39mcoef, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 2054\u001b[0m     gam\u001b[38;5;241m.\u001b[39mfit(X, y, weights)\n\u001b[0;32m   2056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m   2057\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(error) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mon model with params:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(param_grid)\n",
      "File \u001b[1;32mc:\\Users\\athar\\anaconda4\\Lib\\site-packages\\pygam\\pygam.py:912\u001b[0m, in \u001b[0;36mGAM.fit\u001b[1;34m(self, X, y, weights)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatistics_[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm_features\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    911\u001b[0m \u001b[38;5;66;03m# optimize\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pirls(X, y, weights)\n\u001b[0;32m    913\u001b[0m \u001b[38;5;66;03m# if self._opt == 0:\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;66;03m#     self._pirls(X, y, weights)\u001b[39;00m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;66;03m# if self._opt == 1:\u001b[39;00m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;66;03m#     self._pirls_naive(X, y)\u001b[39;00m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\athar\\anaconda4\\Lib\\site-packages\\pygam\\pygam.py:785\u001b[0m, in \u001b[0;36mGAM._pirls\u001b[1;34m(self, X, Y, weights)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_loop_start(\u001b[38;5;28mvars\u001b[39m())\n\u001b[0;32m    784\u001b[0m WB \u001b[38;5;241m=\u001b[39m W\u001b[38;5;241m.\u001b[39mdot(modelmat[mask, :])  \u001b[38;5;66;03m# common matrix product\u001b[39;00m\n\u001b[1;32m--> 785\u001b[0m Q, R \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mqr(WB\u001b[38;5;241m.\u001b[39mtoarray())\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(Q)\u001b[38;5;241m.\u001b[39mall() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(R)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQR decomposition produced NaN or Inf. Check X data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\athar\\anaconda4\\Lib\\site-packages\\numpy\\linalg\\linalg.py:952\u001b[0m, in \u001b[0;36mqr\u001b[1;34m(a, mode)\u001b[0m\n\u001b[0;32m    950\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    951\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_qr)\n\u001b[1;32m--> 952\u001b[0m tau \u001b[38;5;241m=\u001b[39m gufunc(a, signature\u001b[38;5;241m=\u001b[39msignature, extobj\u001b[38;5;241m=\u001b[39mextobj)\n\u001b[0;32m    954\u001b[0m \u001b[38;5;66;03m# handle modes that don't return q\u001b[39;00m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "from pygam import LinearGAM, s, te\n",
    "\n",
    "# =========================================\n",
    "# 1. Split data\n",
    "# =========================================\n",
    "df = data.copy()\n",
    "target_col = \"monthly_spend\"\n",
    "\n",
    "y = df[target_col].reset_index(drop=True)\n",
    "X = df.drop(columns=[target_col]).reset_index(drop=True)\n",
    "\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# =========================================\n",
    "# 2. One-Hot Encode categoricals\n",
    "# =========================================\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "X_train_ohe = preprocessor.fit_transform(X_train)\n",
    "X_test_ohe = preprocessor.transform(X_test)\n",
    "\n",
    "ohe_cols = preprocessor.named_transformers_[\"cat\"].get_feature_names_out(cat_cols)\n",
    "final_cols = list(ohe_cols) + num_cols\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train_ohe, columns=final_cols)\n",
    "X_test_df = pd.DataFrame(X_test_ohe, columns=final_cols)\n",
    "\n",
    "# =========================================\n",
    "# 3. MICE Imputation\n",
    "# =========================================\n",
    "mice = IterativeImputer(\n",
    "    estimator=BayesianRidge(),\n",
    "    max_iter=10,\n",
    "    initial_strategy=\"median\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train_imp = mice.fit_transform(X_train_df)\n",
    "X_test_imp = mice.transform(X_test_df)\n",
    "\n",
    "X_train_imp = pd.DataFrame(X_train_imp, columns=final_cols)\n",
    "X_test_imp = pd.DataFrame(X_test_imp, columns=final_cols)\n",
    "\n",
    "# =========================================\n",
    "# 4. Pick top-k features for interactions\n",
    "#    (based on absolute correlation with y)\n",
    "# =========================================\n",
    "corrs = []\n",
    "for col in final_cols:\n",
    "    c = np.corrcoef(X_train_imp[col], y_train)[0, 1]\n",
    "    if np.isnan(c):\n",
    "        c = 0.0\n",
    "    corrs.append(abs(c))\n",
    "\n",
    "corr_series = pd.Series(corrs, index=final_cols).sort_values(ascending=False)\n",
    "\n",
    "k = 10  # you can try 10, 15, etc.\n",
    "topk_features = corr_series.head(k).index.tolist()\n",
    "print(\"Top-k features for interactions:\", topk_features)\n",
    "\n",
    "# Map feature names to indices\n",
    "feat_to_idx = {name: i for i, name in enumerate(final_cols)}\n",
    "topk_indices = [feat_to_idx[f] for f in topk_features]\n",
    "\n",
    "# =========================================\n",
    "# 5. Build GAM terms: all main effects + interactions among top-k\n",
    "# =========================================\n",
    "n_features = X_train_imp.shape[1]\n",
    "\n",
    "# Main smooth terms for ALL features\n",
    "terms = s(0)\n",
    "for i in range(1, n_features):\n",
    "    terms = terms + s(i)\n",
    "\n",
    "# Add tensor interaction terms ONLY for pairs among top-k\n",
    "for i_idx in range(len(topk_indices)):\n",
    "    for j_idx in range(i_idx + 1, len(topk_indices)):\n",
    "        fi = topk_indices[i_idx]\n",
    "        fj = topk_indices[j_idx]\n",
    "        terms = terms + te(fi, fj)\n",
    "\n",
    "# =========================================\n",
    "# 6. Fit GAM with interactions (GAÂ²M-lite)\n",
    "# =========================================\n",
    "gam = LinearGAM(terms).gridsearch(\n",
    "    X_train_imp.values,\n",
    "    y_train.values,\n",
    "    lam=np.logspace(-3, 3, 7)\n",
    ")\n",
    "\n",
    "print(\"\\nSelected Lambda(s):\", gam.lam)\n",
    "\n",
    "# =========================================\n",
    "# 7. Evaluate on test set\n",
    "# =========================================\n",
    "y_pred_test = gam.predict(X_test_imp.values)\n",
    "\n",
    "rmse = root_mean_squared_error(y_test, y_pred_test)\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"\\nðŸ”¥ GAM (all main effects + interactions among top-{k}) â€” Test RMSE: {rmse:.4f}\")\n",
    "print(f\"ðŸ“ˆ GAM (top-{k} interactions) â€” Test RÂ²: {r2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
